{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dacf8eb",
   "metadata": {},
   "source": [
    "## Heatmap\n",
    "* Count of sales by zip\n",
    "* Average sales by zip\n",
    "* Most/Least Expensive sales by zip last 5 years\n",
    "\n",
    "* In a future version, it would be interesting to layer in demographic information\n",
    "* Would like to put zip codes in a tool tip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf3bc96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e0eb73",
   "metadata": {},
   "source": [
    "### Bringing in and cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9caac65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>basements</th>\n",
       "      <th>building_code_description</th>\n",
       "      <th>category_code_description</th>\n",
       "      <th>census_tract</th>\n",
       "      <th>central_air</th>\n",
       "      <th>depth</th>\n",
       "      <th>exempt_building</th>\n",
       "      <th>exempt_land</th>\n",
       "      <th>exterior_condition</th>\n",
       "      <th>fireplaces</th>\n",
       "      <th>...</th>\n",
       "      <th>topography</th>\n",
       "      <th>total_area</th>\n",
       "      <th>total_livable_area</th>\n",
       "      <th>type_heater</th>\n",
       "      <th>unit</th>\n",
       "      <th>view_type</th>\n",
       "      <th>year_built</th>\n",
       "      <th>year_built_estimate</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>zoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D</td>\n",
       "      <td>ROW 3 STY MASONRY</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>241.0</td>\n",
       "      <td>N</td>\n",
       "      <td>67.0</td>\n",
       "      <td>49200</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>938.00</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>1895</td>\n",
       "      <td>Y</td>\n",
       "      <td>19144</td>\n",
       "      <td>RSA5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ROW 2 STY MASONRY</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>201.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>1044.00</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>1940</td>\n",
       "      <td>Y</td>\n",
       "      <td>19140</td>\n",
       "      <td>RM1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H</td>\n",
       "      <td>ROW B/GAR 2 STY MASONRY</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>281.0</td>\n",
       "      <td>N</td>\n",
       "      <td>95.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>1686.53</td>\n",
       "      <td>1633.0</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>1940</td>\n",
       "      <td>Y</td>\n",
       "      <td>19141</td>\n",
       "      <td>RSA3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ROW 2 STY MASONRY</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>293.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>2165.62</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>1940</td>\n",
       "      <td>Y</td>\n",
       "      <td>19124</td>\n",
       "      <td>RSA5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ROW 2 STY MASONRY</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>F</td>\n",
       "      <td>1264.00</td>\n",
       "      <td>960.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>1920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19142</td>\n",
       "      <td>RM1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  basements building_code_description category_code_description  census_tract  \\\n",
       "0         D         ROW 3 STY MASONRY             Single Family         241.0   \n",
       "1       NaN         ROW 2 STY MASONRY             Single Family         201.0   \n",
       "2         H   ROW B/GAR 2 STY MASONRY             Single Family         281.0   \n",
       "3       NaN         ROW 2 STY MASONRY             Single Family         293.0   \n",
       "4       NaN         ROW 2 STY MASONRY             Single Family          62.0   \n",
       "\n",
       "  central_air  depth  exempt_building  exempt_land  exterior_condition  \\\n",
       "0           N   67.0            49200            0                 4.0   \n",
       "1         NaN   70.0                0            0                 4.0   \n",
       "2           N   95.5                0            0                 4.0   \n",
       "3         NaN  112.5                0            0                 4.0   \n",
       "4         NaN   79.0                0            0                 4.0   \n",
       "\n",
       "   fireplaces  ...  topography total_area  total_livable_area type_heater  \\\n",
       "0         0.0  ...           F     938.00              1344.0           A   \n",
       "1         0.0  ...           F    1044.00              1190.0         NaN   \n",
       "2         0.0  ...           F    1686.53              1633.0           B   \n",
       "3         0.0  ...           F    2165.62              1320.0           B   \n",
       "4         0.0  ...           F    1264.00               960.0         NaN   \n",
       "\n",
       "   unit  view_type year_built  year_built_estimate  zip_code  zoning  \n",
       "0   NaN          I       1895                    Y     19144    RSA5  \n",
       "1   NaN          I       1940                    Y     19140     RM1  \n",
       "2   NaN          I       1940                    Y     19141    RSA3  \n",
       "3   NaN          I       1940                    Y     19124    RSA5  \n",
       "4   NaN          I       1920                  NaN     19142     RM1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bring in housing dataframe\n",
    "housingFile = 'source_data/housing_data_cleaned.csv'\n",
    "\n",
    "# Read in file\n",
    "housingDF = pd.read_csv(housingFile, low_memory=False)\n",
    "housingDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "321c1036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2020-09-28\n",
       "1    2020-09-25\n",
       "2    2020-09-25\n",
       "3    2020-09-24\n",
       "4    2020-09-24\n",
       "Name: sale_date, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formatting Date\n",
    "housingDF['sale_date'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a9e837",
   "metadata": {},
   "source": [
    "### Count of sales by zip\n",
    "* This explores the total number of home sales by zip code\n",
    "* Across all dates in the file\n",
    "* This will show overtime, where most homes are sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0965f697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>sale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19102</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19103</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19104</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19106</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19107</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_code  sale_price\n",
       "0    19102          16\n",
       "1    19103         223\n",
       "2    19104         640\n",
       "3    19106          47\n",
       "4    19107          67"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate total sales by zip code\n",
    "\n",
    "# Create df to use for grouping\n",
    "salesCount = housingDF[['zip_code','sale_price']]\n",
    "\n",
    "salesCount = salesCount.dropna(how='any')\n",
    "\n",
    "# Convert to string in main ETL\n",
    "salesCount['zip_code'] = salesCount['zip_code'].astype('Int64').astype('str')\n",
    "\n",
    "\n",
    "# Create groupby object\n",
    "salesCount_groupby = salesCount.groupby('zip_code')\n",
    "\n",
    "# Create grouped data frame with count of sales, mean, median sale price\n",
    "salesCount_groupbyDF = salesCount_groupby.count()\n",
    "salesCount_groupbyDF = salesCount_groupbyDF.reset_index()\n",
    "salesCount_groupbyDF\n",
    "\n",
    "# Add zip codes 19109 and 19102, so that GeoJSON will work - not in original df but in GeoJSON file\n",
    "salesCount_groupbyDF = salesCount_groupbyDF.append({'zip_code':'19109','sale_price':0},ignore_index=True)\n",
    "salesCount_groupbyDF = salesCount_groupbyDF.append({'zip_code':'19112','sale_price':0},ignore_index=True)\n",
    "\n",
    "#salesCount_groupbyDF['zip_code'].value_counts()\n",
    "\n",
    "salesCount_groupbyDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fefa9d7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-53a59a54da05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# locate file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'source_data/Zipcodes_Poly.geojson'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjsonFile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjsonFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# create base map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# locate file\n",
    "with open('source_data/Zipcodes_Poly.geojson','r') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "\n",
    "# create base map\n",
    "salesCount_map = folium.Map(location=[39.9526, -75.1652], zoom_start = 11)\n",
    "\n",
    "# generate map\n",
    "choropleth = folium.Choropleth(\n",
    "    geo_data = data,\n",
    "    data = salesCount_groupbyDF,\n",
    "    columns = ['zip_code','sale_price'],\n",
    "    legend_name='Number of Home Sales by Zip Code',\n",
    "    key_on = 'feature.properties.CODE',\n",
    "    fill_color = 'YlGnBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    )\n",
    "\n",
    "folium.LayerControl().add_to(salesCount_map)\n",
    "\n",
    "# Display map\n",
    "salesCount_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619617cc",
   "metadata": {},
   "source": [
    "### Average of sales by zip\n",
    "* This explores the average sale price by zip code\n",
    "* Across all dates in the file\n",
    "* This will show overtime the average price of a residence sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed0880ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>sale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19102</td>\n",
       "      <td>9.102812e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19103</td>\n",
       "      <td>1.340693e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19104</td>\n",
       "      <td>2.709431e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19106</td>\n",
       "      <td>1.040698e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19107</td>\n",
       "      <td>9.797343e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_code    sale_price\n",
       "0    19102  9.102812e+05\n",
       "1    19103  1.340693e+06\n",
       "2    19104  2.709431e+05\n",
       "3    19106  1.040698e+06\n",
       "4    19107  9.797343e+05"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate total sales by zip code\n",
    "\n",
    "# Create df to use for grouping\n",
    "salesAvg = housingDF[['zip_code','sale_price']]\n",
    "\n",
    "salesAvg = salesAvg.dropna(how='any')\n",
    "\n",
    "# Convert to string in main ETL\n",
    "salesAvg['zip_code'] = salesAvg['zip_code'].astype('Int64').astype('str')\n",
    "\n",
    "\n",
    "# Create groupby object\n",
    "salesAvg_groupby = salesAvg.groupby('zip_code')\n",
    "\n",
    "# Create grouped data frame with count of sales, mean, median sale price\n",
    "salesAvg_groupbyDF = salesAvg_groupby.mean()\n",
    "salesAvg_groupbyDF = salesAvg_groupbyDF.reset_index()\n",
    "salesAvg_groupbyDF\n",
    "\n",
    "# Add zip codes 19109 and 19102, so that GeoJSON will work - not in original df but in GeoJSON file\n",
    "salesAvg_groupbyDF = salesAvg_groupbyDF.append({'zip_code':'19109','sale_price':0},ignore_index=True)\n",
    "salesAvg_groupbyDF = salesAvg_groupbyDF.append({'zip_code':'19112','sale_price':0},ignore_index=True)\n",
    "\n",
    "salesAvg_groupbyDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89c5c266",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 7 column 1 (char 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-becdafbaea81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load in GeoJSON file for map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'source_data/Zipcodes_Poly.geojson'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjsonFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create folium map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 7 column 1 (char 6)"
     ]
    }
   ],
   "source": [
    "# Load in GeoJSON file for map\n",
    "with open('source_data/Zipcodes_Poly.geojson','r') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    \n",
    "# Create folium map\n",
    "m = folium.Map(location=[39.9526, -75.1652],zoom_start=11)\n",
    "m.choropleth(\n",
    "    geo_data=data,\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    data=salesAvg_groupbyDF,\n",
    "    key_on='feature.properties.CODE',\n",
    "    columns=['zip_code','sale_price'],\n",
    "    fill_color='YlGnBu',\n",
    "    legend_name='Average Home Sales by Zip Code'\n",
    ")\n",
    "\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061cf2b2",
   "metadata": {},
   "source": [
    "### Most/Least Expensive sales by zip last 5 years\n",
    "* Exploring the most and least expensive sales by zip code over 5 years\n",
    "* 2016, 2017, 2018, 2019 and 2020\n",
    "* This can show a trend in housing sales over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb61448",
   "metadata": {},
   "source": [
    "------\n",
    "* 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09b331d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19102</td>\n",
       "      <td>2016-06-24</td>\n",
       "      <td>1300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19103</td>\n",
       "      <td>2016-12-09</td>\n",
       "      <td>4500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19104</td>\n",
       "      <td>2016-12-22</td>\n",
       "      <td>1030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19106</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19107</td>\n",
       "      <td>2016-12-20</td>\n",
       "      <td>707500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_code   sale_date  sale_price\n",
       "0    19102  2016-06-24     1300000\n",
       "1    19103  2016-12-09     4500000\n",
       "2    19104  2016-12-22     1030000\n",
       "3    19106  2016-08-16      725000\n",
       "4    19107  2016-12-20      707500"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MAX VALUES\n",
    "# Aggregate total sales by date\n",
    "\n",
    "# Create df to use for grouping\n",
    "saleDate = housingDF[['zip_code', 'sale_date','sale_price']]\n",
    "\n",
    "saleDate = saleDate.dropna(how='any')\n",
    "\n",
    "# Convert to string in main ETL\n",
    "saleDate['zip_code'] = saleDate['zip_code'].astype('Int64').astype('str')\n",
    "\n",
    "# Filter dataframe (2016 - 2020)\n",
    "saleDate2016 = saleDate[(saleDate['sale_date'] >= '2015-12-31') & (saleDate['sale_date'] <= '2016-12-31')]\n",
    "\n",
    "# Create groupby object\n",
    "saleDate2016_groupby = saleDate2016.groupby('zip_code')\n",
    "\n",
    "# Create grouped data frame with count of sales, mean, median sale price\n",
    "saleDate2016MAX_groupbyDF = saleDate2016_groupby.max()\n",
    "saleDate2016MAX_groupbyDF = saleDate2016MAX_groupbyDF.reset_index()\n",
    "saleDate2016MAX_groupbyDF\n",
    "\n",
    "# Add zip codes 19109 and 19102, so that GeoJSON will work - not in original df but in GeoJSON file\n",
    "saleDate2016MAX_groupbyDF = saleDate2016MAX_groupbyDF.append({'zip_code':'19109','sale_price':0},ignore_index=True)\n",
    "saleDate2016MAX_groupbyDF = saleDate2016MAX_groupbyDF.append({'zip_code':'19112','sale_price':0},ignore_index=True)\n",
    "\n",
    "saleDate2016MAX_groupbyDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73debf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in GeoJSON file for map\n",
    "with open('source_data/Zipcodes_Poly.geojson','r') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    \n",
    "# Create folium map\n",
    "m = folium.Map(location=[39.9526, -75.1652],zoom_start=11)\n",
    "m.choropleth(\n",
    "    geo_data=data,\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    data=saleDate2016MAX_groupbyDF,\n",
    "    key_on='feature.properties.CODE',\n",
    "    columns=['zip_code','sale_price'],\n",
    "    fill_color='YlGnBu',\n",
    "    legend_name='Most Expensive Home Sold by Zip, 2016'\n",
    ")\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc9cafd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19102</td>\n",
       "      <td>2016-03-31</td>\n",
       "      <td>302500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19103</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>164900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19104</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>1107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19106</td>\n",
       "      <td>2016-02-26</td>\n",
       "      <td>365000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19107</td>\n",
       "      <td>2016-01-18</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_code   sale_date  sale_price\n",
       "0    19102  2016-03-31      302500\n",
       "1    19103  2016-01-18      164900\n",
       "2    19104  2016-01-05        1107\n",
       "3    19106  2016-02-26      365000\n",
       "4    19107  2016-01-18      200000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MIN VALUES\n",
    "# Aggregate total sales by date\n",
    "\n",
    "# Create df to use for grouping\n",
    "saleDate = housingDF[['zip_code', 'sale_date','sale_price']]\n",
    "\n",
    "saleDate = saleDate.dropna(how='any')\n",
    "\n",
    "# Convert to string in main ETL\n",
    "saleDate['zip_code'] = saleDate['zip_code'].astype('Int64').astype('str')\n",
    "\n",
    "# Filter dataframe (2016 - 2020)\n",
    "saleDate2016 = saleDate[(saleDate['sale_date'] >= '2015-12-31') & (saleDate['sale_date'] <= '2016-12-31')]\n",
    "\n",
    "# Create groupby object\n",
    "saleDate2016_groupby = saleDate2016.groupby('zip_code')\n",
    "\n",
    "# Create grouped data frame with count of sales, mean, median sale price\n",
    "saleDate2016MIN_groupbyDF = saleDate2016_groupby.min()\n",
    "saleDate2016MIN_groupbyDF = saleDate2016MIN_groupbyDF.reset_index()\n",
    "saleDate2016MIN_groupbyDF\n",
    "\n",
    "# Add zip codes 19109 and 19102, so that GeoJSON will work - not in original df but in GeoJSON file\n",
    "saleDate2016MIN_groupbyDF = saleDate2016MIN_groupbyDF.append({'zip_code':'19109','sale_price':0},ignore_index=True)\n",
    "saleDate2016MIN_groupbyDF = saleDate2016MIN_groupbyDF.append({'zip_code':'19112','sale_price':0},ignore_index=True)\n",
    "\n",
    "saleDate2016MIN_groupbyDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e43d592",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 7 column 1 (char 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-952b2412ada5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load in GeoJSON file for map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'source_data/Zipcodes_Poly.geojson'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjsonFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create folium map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 7 column 1 (char 6)"
     ]
    }
   ],
   "source": [
    "# Load in GeoJSON file for map\n",
    "with open('source_data/Zipcodes_Poly.geojson','r') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    \n",
    "# Create folium map\n",
    "m = folium.Map(location=[39.9526, -75.1652],zoom_start=11)\n",
    "m.choropleth(\n",
    "    geo_data=data,\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    data=saleDate2016MIN_groupbyDF,\n",
    "    key_on='feature.properties.CODE',\n",
    "    columns=['zip_code','sale_price'],\n",
    "    fill_color='YlGnBu',\n",
    "    legend_name='Least Expensive Home Sold by Zip, 2016'\n",
    ")\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed0f60e",
   "metadata": {},
   "source": [
    "### Most/Least Expensive sales by zip last 5 years\n",
    "* 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fc65900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19102</td>\n",
       "      <td>2017-09-20</td>\n",
       "      <td>1305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19103</td>\n",
       "      <td>2017-12-14</td>\n",
       "      <td>5290300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19104</td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>1625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19106</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>2168000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19107</td>\n",
       "      <td>2017-11-15</td>\n",
       "      <td>825000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_code   sale_date  sale_price\n",
       "0    19102  2017-09-20     1305000\n",
       "1    19103  2017-12-14     5290300\n",
       "2    19104  2017-12-28     1625000\n",
       "3    19106  2017-12-27     2168000\n",
       "4    19107  2017-11-15      825000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MAX VALUES\n",
    "# Aggregate total sales by date\n",
    "\n",
    "# Create df to use for grouping\n",
    "saleDate = housingDF[['zip_code', 'sale_date','sale_price']]\n",
    "\n",
    "saleDate = saleDate.dropna(how='any')\n",
    "\n",
    "# Convert to string in main ETL\n",
    "saleDate['zip_code'] = saleDate['zip_code'].astype('Int64').astype('str')\n",
    "\n",
    "# Filter dataframe (2016 - 2020)\n",
    "saleDate2017 = saleDate[(saleDate['sale_date'] > '2016-12-31') & (saleDate['sale_date'] <= '2017-12-31')]\n",
    "\n",
    "# Create groupby object\n",
    "saleDate2017_groupby = saleDate2017.groupby('zip_code')\n",
    "\n",
    "# Create grouped data frame with count of sales, mean, median sale price\n",
    "saleDate2017MAX_groupbyDF = saleDate2017_groupby.max()\n",
    "saleDate2017MAX_groupbyDF = saleDate2017MAX_groupbyDF.reset_index()\n",
    "saleDate2017MAX_groupbyDF\n",
    "\n",
    "# Add zip codes 19109 and 19102, so that GeoJSON will work - not in original df but in GeoJSON file\n",
    "saleDate2017MAX_groupbyDF = saleDate2017MAX_groupbyDF.append({'zip_code':'19109','sale_price':0},ignore_index=True)\n",
    "saleDate2017MAX_groupbyDF = saleDate2017MAX_groupbyDF.append({'zip_code':'19112','sale_price':0},ignore_index=True)\n",
    "\n",
    "saleDate2017MAX_groupbyDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2ca10860",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 7 column 1 (char 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0602b2fddbb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load in GeoJSON file for map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'source_data/Zipcodes_Poly.geojson'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjsonFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjsonFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create folium map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.8/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 7 column 1 (char 6)"
     ]
    }
   ],
   "source": [
    "# Load in GeoJSON file for map\n",
    "with open('source_data/Zipcodes_Poly.geojson','r') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    \n",
    "# Create folium map\n",
    "m = folium.Map(location=[39.9526, -75.1652],zoom_start=11)\n",
    "m.choropleth(\n",
    "    geo_data=data,\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    data=saleDate2017MAX_groupbyDF,\n",
    "    key_on='feature.properties.CODE',\n",
    "    columns=['zip_code','sale_price'],\n",
    "    fill_color='YlGnBu',\n",
    "    legend_name='Most Expensive Homes Sold by Zip, 2017'\n",
    ")\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ff019757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19102</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19103</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19104</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19106</td>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19107</td>\n",
       "      <td>2017-02-15</td>\n",
       "      <td>260000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_code   sale_date  sale_price\n",
       "0    19102  2017-01-09      420000\n",
       "1    19103  2017-01-31      265000\n",
       "2    19104  2017-01-01        5000\n",
       "3    19106  2017-04-21      195000\n",
       "4    19107  2017-02-15      260000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MIN VALUES\n",
    "# Aggregate total sales by date\n",
    "\n",
    "# Create df to use for grouping\n",
    "saleDate = housingDF[['zip_code', 'sale_date','sale_price']]\n",
    "\n",
    "saleDate = saleDate.dropna(how='any')\n",
    "\n",
    "# Convert to string in main ETL\n",
    "saleDate['zip_code'] = saleDate['zip_code'].astype('Int64').astype('str')\n",
    "\n",
    "# Filter dataframe (2016 - 2020)\n",
    "saleDate2017 = saleDate[(saleDate['sale_date'] > '2016-12-31') & (saleDate['sale_date'] <= '2017-12-31')]\n",
    "\n",
    "# Create groupby object\n",
    "saleDate2017_groupby = saleDate2017.groupby('zip_code')\n",
    "\n",
    "# Create grouped data frame with count of sales, mean, median sale price\n",
    "saleDate2017MIN_groupbyDF = saleDate2017_groupby.min()\n",
    "saleDate2017MIN_groupbyDF = saleDate2017MIN_groupbyDF.reset_index()\n",
    "saleDate2017MIN_groupbyDF\n",
    "\n",
    "# Add zip codes 19109 and 19102, so that GeoJSON will work - not in original df but in GeoJSON file\n",
    "saleDate2017MIN_groupbyDF = saleDate2017MIN_groupbyDF.append({'zip_code':'19109','sale_price':0},ignore_index=True)\n",
    "saleDate2017MIN_groupbyDF = saleDate2017MIN_groupbyDF.append({'zip_code':'19112','sale_price':0},ignore_index=True)\n",
    "\n",
    "saleDate2017MIN_groupbyDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e50febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in GeoJSON file for map\n",
    "with open('source_data/Zipcodes_Poly.geojson','r') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    \n",
    "# Create folium map\n",
    "m = folium.Map(location=[39.9526, -75.1652],zoom_start=11)\n",
    "m.choropleth(\n",
    "    geo_data=data,\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    data=saleDate2017MIN_groupbyDF,\n",
    "    key_on='feature.properties.CODE',\n",
    "    columns=['zip_code','sale_price'],\n",
    "    fill_color='YlGnBu',\n",
    "    legend_name='Least Expensive Homes Sold by Zip, 2017'\n",
    ")\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7daffee",
   "metadata": {},
   "source": [
    "### Most/Least Expensive sales by zip last 5 years\n",
    "* 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be185ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19102</td>\n",
       "      <td>2018-12-04</td>\n",
       "      <td>2035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19103</td>\n",
       "      <td>2018-12-17</td>\n",
       "      <td>7000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19104</td>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>3300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19106</td>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>2000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19107</td>\n",
       "      <td>2018-12-19</td>\n",
       "      <td>6500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_code   sale_date  sale_price\n",
       "0    19102  2018-12-04     2035000\n",
       "1    19103  2018-12-17     7000000\n",
       "2    19104  2018-12-28     3300000\n",
       "3    19106  2018-12-27     2000000\n",
       "4    19107  2018-12-19     6500000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MAX VALUES\n",
    "# Aggregate total sales by date\n",
    "\n",
    "# Create df to use for grouping\n",
    "saleDate = housingDF[['zip_code', 'sale_date','sale_price']]\n",
    "\n",
    "saleDate = saleDate.dropna(how='any')\n",
    "\n",
    "# Convert to string in main ETL\n",
    "saleDate['zip_code'] = saleDate['zip_code'].astype('Int64').astype('str')\n",
    "\n",
    "# Filter dataframe (2016 - 2020)\n",
    "saleDate2018 = saleDate[(saleDate['sale_date'] > '2017-12-31') & (saleDate['sale_date'] <= '2018-12-31')]\n",
    "\n",
    "# Create groupby object\n",
    "saleDate2018_groupby = saleDate2018.groupby('zip_code')\n",
    "\n",
    "# Create grouped data frame with count of sales, mean, median sale price\n",
    "saleDate2018MAX_groupbyDF = saleDate2018_groupby.max()\n",
    "saleDate2018MAX_groupbyDF = saleDate2018MAX_groupbyDF.reset_index()\n",
    "saleDate2018MAX_groupbyDF\n",
    "\n",
    "# Add zip codes 19109 and 19102, so that GeoJSON will work - not in original df but in GeoJSON file\n",
    "saleDate2018MAX_groupbyDF = saleDate2018MAX_groupbyDF.append({'zip_code':'19109','sale_price':0},ignore_index=True)\n",
    "saleDate2018MAX_groupbyDF = saleDate2018MAX_groupbyDF.append({'zip_code':'19112','sale_price':0},ignore_index=True)\n",
    "\n",
    "saleDate2018MAX_groupbyDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb67a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in GeoJSON file for map\n",
    "with open('source_data/Zipcodes_Poly.geojson','r') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    \n",
    "# Create folium map\n",
    "m = folium.Map(location=[39.9526, -75.1652],zoom_start=11)\n",
    "m.choropleth(\n",
    "    geo_data=data,\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    data=saleDate2018MAX_groupbyDF,\n",
    "    key_on='feature.properties.CODE',\n",
    "    columns=['zip_code','sale_price'],\n",
    "    fill_color='YlGnBu',\n",
    "    legend_name='Most Expensive Homes Sold by Zip, 2018'\n",
    ")\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca8f48c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19102</td>\n",
       "      <td>2018-04-26</td>\n",
       "      <td>295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19103</td>\n",
       "      <td>2018-01-03</td>\n",
       "      <td>105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19104</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19106</td>\n",
       "      <td>2018-01-05</td>\n",
       "      <td>404500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19107</td>\n",
       "      <td>2018-01-19</td>\n",
       "      <td>238500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_code   sale_date  sale_price\n",
       "0    19102  2018-04-26      295000\n",
       "1    19103  2018-01-03      105800\n",
       "2    19104  2018-01-05        1000\n",
       "3    19106  2018-01-05      404500\n",
       "4    19107  2018-01-19      238500"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MIN VALUES\n",
    "# Aggregate total sales by date\n",
    "\n",
    "# Create df to use for grouping\n",
    "saleDate = housingDF[['zip_code', 'sale_date','sale_price']]\n",
    "\n",
    "saleDate = saleDate.dropna(how='any')\n",
    "\n",
    "# Convert to string in main ETL\n",
    "saleDate['zip_code'] = saleDate['zip_code'].astype('Int64').astype('str')\n",
    "\n",
    "# Filter dataframe (2016 - 2020)\n",
    "saleDate2018 = saleDate[(saleDate['sale_date'] > '2017-12-31') & (saleDate['sale_date'] <= '2018-12-31')]\n",
    "\n",
    "# Create groupby object\n",
    "saleDate2018_groupby = saleDate2018.groupby('zip_code')\n",
    "\n",
    "# Create grouped data frame with count of sales, mean, median sale price\n",
    "saleDate2018MIN_groupbyDF = saleDate2018_groupby.min()\n",
    "saleDate2018MIN_groupbyDF = saleDate2018MIN_groupbyDF.reset_index()\n",
    "saleDate2018MIN_groupbyDF\n",
    "\n",
    "# Add zip codes 19109 and 19102, so that GeoJSON will work - not in original df but in GeoJSON file\n",
    "saleDate2018MIN_groupbyDF = saleDate2018MIN_groupbyDF.append({'zip_code':'19109','sale_price':0},ignore_index=True)\n",
    "saleDate2018MIN_groupbyDF = saleDate2018MIN_groupbyDF.append({'zip_code':'19112','sale_price':0},ignore_index=True)\n",
    "\n",
    "saleDate2018MIN_groupbyDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11216e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in GeoJSON file for map\n",
    "with open('source_data/Zipcodes_Poly.geojson','r') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    \n",
    "# Create folium map\n",
    "m = folium.Map(location=[39.9526, -75.1652],zoom_start=11)\n",
    "m.choropleth(\n",
    "    geo_data=data,\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    data=saleDate2018MIN_groupbyDF,\n",
    "    key_on='feature.properties.CODE',\n",
    "    columns=['zip_code','sale_price'],\n",
    "    fill_color='YlGnBu',\n",
    "    legend_name='Least Expensive Homes Sold by Zip, 2018'\n",
    ")\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d052b",
   "metadata": {},
   "source": [
    "### Most/Least Expensive sales by zip last 5 years\n",
    "* 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9090876e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19102</td>\n",
       "      <td>2019-05-22</td>\n",
       "      <td>825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19103</td>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>2700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19104</td>\n",
       "      <td>2019-12-20</td>\n",
       "      <td>5520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19106</td>\n",
       "      <td>2019-12-12</td>\n",
       "      <td>2200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19107</td>\n",
       "      <td>2019-10-25</td>\n",
       "      <td>405000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_code   sale_date  sale_price\n",
       "0    19102  2019-05-22      825000\n",
       "1    19103  2019-12-30     2700000\n",
       "2    19104  2019-12-20     5520000\n",
       "3    19106  2019-12-12     2200000\n",
       "4    19107  2019-10-25      405000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MAX VALUES\n",
    "# Aggregate total sales by date\n",
    "\n",
    "# Create df to use for grouping\n",
    "saleDate = housingDF[['zip_code', 'sale_date','sale_price']]\n",
    "\n",
    "saleDate = saleDate.dropna(how='any')\n",
    "\n",
    "# Convert to string in main ETL\n",
    "saleDate['zip_code'] = saleDate['zip_code'].astype('Int64').astype('str')\n",
    "\n",
    "# Filter dataframe (2016 - 2020)\n",
    "saleDate2019 = saleDate[(saleDate['sale_date'] > '2018-12-31') & (saleDate['sale_date'] <= '2019-12-31')]\n",
    "\n",
    "# Create groupby object\n",
    "saleDate2019_groupby = saleDate2019.groupby('zip_code')\n",
    "\n",
    "# Create grouped data frame with count of sales, mean, median sale price\n",
    "saleDate2019MAX_groupbyDF = saleDate2019_groupby.max()\n",
    "saleDate2019MAX_groupbyDF = saleDate2019MAX_groupbyDF.reset_index()\n",
    "saleDate2019MAX_groupbyDF\n",
    "\n",
    "# Add zip codes 19109 and 19102, so that GeoJSON will work - not in original df but in GeoJSON file\n",
    "saleDate2019MAX_groupbyDF = saleDate2019MAX_groupbyDF.append({'zip_code':'19109','sale_price':0},ignore_index=True)\n",
    "saleDate2019MAX_groupbyDF = saleDate2019MAX_groupbyDF.append({'zip_code':'19112','sale_price':0},ignore_index=True)\n",
    "\n",
    "saleDate2019MAX_groupbyDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34a15cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in GeoJSON file for map\n",
    "with open('source_data/Zipcodes_Poly.geojson','r') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    \n",
    "# Create folium map\n",
    "m = folium.Map(location=[39.9526, -75.1652],zoom_start=11)\n",
    "m.choropleth(\n",
    "    geo_data=data,\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    data=saleDate2019MAX_groupbyDF,\n",
    "    key_on='feature.properties.CODE',\n",
    "    columns=['zip_code','sale_price'],\n",
    "    fill_color='YlGnBu',\n",
    "    legend_name='Most Expensive Homes Sold by Zip, 2019'\n",
    ")\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "903de62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19102</td>\n",
       "      <td>2019-05-22</td>\n",
       "      <td>825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19103</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19104</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19106</td>\n",
       "      <td>2019-01-24</td>\n",
       "      <td>410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19107</td>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>134000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_code   sale_date  sale_price\n",
       "0    19102  2019-05-22      825000\n",
       "1    19103  2019-01-03      310000\n",
       "2    19104  2019-01-08        2500\n",
       "3    19106  2019-01-24      410000\n",
       "4    19107  2019-03-26      134000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MIN VALUES\n",
    "# Aggregate total sales by date\n",
    "\n",
    "# Create df to use for grouping\n",
    "saleDate = housingDF[['zip_code', 'sale_date','sale_price']]\n",
    "\n",
    "saleDate = saleDate.dropna(how='any')\n",
    "\n",
    "# Convert to string in main ETL\n",
    "saleDate['zip_code'] = saleDate['zip_code'].astype('Int64').astype('str')\n",
    "\n",
    "# Filter dataframe (2016 - 2020)\n",
    "saleDate2019 = saleDate[(saleDate['sale_date'] > '2018-12-31') & (saleDate['sale_date'] <= '2019-12-31')]\n",
    "\n",
    "# Create groupby object\n",
    "saleDate2019_groupby = saleDate2019.groupby('zip_code')\n",
    "\n",
    "# Create grouped data frame with count of sales, mean, median sale price\n",
    "saleDate2019MIN_groupbyDF = saleDate2019_groupby.min()\n",
    "saleDate2019MIN_groupbyDF = saleDate2019MIN_groupbyDF.reset_index()\n",
    "saleDate2019MIN_groupbyDF\n",
    "\n",
    "# Add zip codes 19109 and 19102, so that GeoJSON will work - not in original df but in GeoJSON file\n",
    "saleDate2019MIN_groupbyDF = saleDate2019MIN_groupbyDF.append({'zip_code':'19109','sale_price':0},ignore_index=True)\n",
    "saleDate2019MIN_groupbyDF = saleDate2019MIN_groupbyDF.append({'zip_code':'19112','sale_price':0},ignore_index=True)\n",
    "\n",
    "saleDate2019MIN_groupbyDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c25d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in GeoJSON file for map\n",
    "with open('source_data/Zipcodes_Poly.geojson','r') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    \n",
    "# Create folium map\n",
    "m = folium.Map(location=[39.9526, -75.1652],zoom_start=11)\n",
    "m.choropleth(\n",
    "    geo_data=data,\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    data=saleDate2019MIN_groupbyDF,\n",
    "    key_on='feature.properties.CODE',\n",
    "    columns=['zip_code','sale_price'],\n",
    "    fill_color='YlGnBu',\n",
    "    legend_name='Least Expensive Homes Sold by Zip, 2019'\n",
    ")\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7f89ae",
   "metadata": {},
   "source": [
    "### Most/Least Expensive sales by zip last 5 years\n",
    "* 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0d06e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19102</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>1595000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19103</td>\n",
       "      <td>2020-08-24</td>\n",
       "      <td>2425000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19104</td>\n",
       "      <td>2020-09-22</td>\n",
       "      <td>1350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19106</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>2100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19107</td>\n",
       "      <td>2020-06-25</td>\n",
       "      <td>1330000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_code   sale_date  sale_price\n",
       "0    19102  2020-01-07     1595000\n",
       "1    19103  2020-08-24     2425000\n",
       "2    19104  2020-09-22     1350000\n",
       "3    19106  2020-02-21     2100000\n",
       "4    19107  2020-06-25     1330000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MAX VALUES\n",
    "# Aggregate total sales by date\n",
    "\n",
    "# Create df to use for grouping\n",
    "saleDate = housingDF[['zip_code', 'sale_date','sale_price']]\n",
    "\n",
    "saleDate = saleDate.dropna(how='any')\n",
    "\n",
    "# Convert to string in main ETL\n",
    "saleDate['zip_code'] = saleDate['zip_code'].astype('Int64').astype('str')\n",
    "\n",
    "# Filter dataframe (2016 - 2020)\n",
    "saleDate2020 = saleDate[(saleDate['sale_date'] > '2019-12-31') & (saleDate['sale_date'] <= '2020-12-31')]\n",
    "\n",
    "# Create groupby object\n",
    "saleDate2020_groupby = saleDate2020.groupby('zip_code')\n",
    "\n",
    "# Create grouped data frame with count of sales, mean, median sale price\n",
    "saleDate2020MAX_groupbyDF = saleDate2020_groupby.max()\n",
    "saleDate2020MAX_groupbyDF = saleDate2020MAX_groupbyDF.reset_index()\n",
    "saleDate2020MAX_groupbyDF\n",
    "\n",
    "# Add zip codes 19109 and 19102, so that GeoJSON will work - not in original df but in GeoJSON file\n",
    "saleDate2020MAX_groupbyDF = saleDate2020MAX_groupbyDF.append({'zip_code':'19109','sale_price':0},ignore_index=True)\n",
    "saleDate2020MAX_groupbyDF = saleDate2020MAX_groupbyDF.append({'zip_code':'19112','sale_price':0},ignore_index=True)\n",
    "\n",
    "saleDate2020MAX_groupbyDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ec3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in GeoJSON file for map\n",
    "with open('source_data/Zipcodes_Poly.geojson','r') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    \n",
    "# Create folium map\n",
    "m = folium.Map(location=[39.9526, -75.1652],zoom_start=11)\n",
    "m.choropleth(\n",
    "    geo_data=data,\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    data=saleDate2020MAX_groupbyDF,\n",
    "    key_on='feature.properties.CODE',\n",
    "    columns=['zip_code','sale_price'],\n",
    "    fill_color='YlGnBu',\n",
    "    legend_name='Most Expensive Homes Sold by Zip, 2020'\n",
    ")\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "912be3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19102</td>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>1595000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19103</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19104</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19106</td>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19107</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_code   sale_date  sale_price\n",
       "0    19102  2020-01-07     1595000\n",
       "1    19103  2020-01-06      505000\n",
       "2    19104  2020-01-04        1500\n",
       "3    19106  2020-01-17      600000\n",
       "4    19107  2020-03-07      250000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## MIN VALUES\n",
    "# Aggregate total sales by date\n",
    "\n",
    "# Create df to use for grouping\n",
    "saleDate = housingDF[['zip_code', 'sale_date','sale_price']]\n",
    "\n",
    "saleDate = saleDate.dropna(how='any')\n",
    "\n",
    "# Convert to string in main ETL\n",
    "saleDate['zip_code'] = saleDate['zip_code'].astype('Int64').astype('str')\n",
    "\n",
    "# Filter dataframe (2016 - 2020)\n",
    "saleDate2020 = saleDate[(saleDate['sale_date'] > '2019-12-31') & (saleDate['sale_date'] <= '2020-12-31')]\n",
    "\n",
    "# Create groupby object\n",
    "saleDate2020_groupby = saleDate2020.groupby('zip_code')\n",
    "\n",
    "# Create grouped data frame with count of sales, mean, median sale price\n",
    "saleDate2020MIN_groupbyDF = saleDate2020_groupby.min()\n",
    "saleDate2020MIN_groupbyDF = saleDate2020MIN_groupbyDF.reset_index()\n",
    "saleDate2020MIN_groupbyDF\n",
    "\n",
    "# Add zip codes 19109 and 19102, so that GeoJSON will work - not in original df but in GeoJSON file\n",
    "saleDate2020MIN_groupbyDF = saleDate2020MIN_groupbyDF.append({'zip_code':'19109','sale_price':0},ignore_index=True)\n",
    "saleDate2020MIN_groupbyDF = saleDate2020MIN_groupbyDF.append({'zip_code':'19112','sale_price':0},ignore_index=True)\n",
    "\n",
    "saleDate2020MIN_groupbyDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fee3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in GeoJSON file for map\n",
    "with open('source_data/Zipcodes_Poly.geojson','r') as jsonFile:\n",
    "    data = json.load(jsonFile)\n",
    "    \n",
    "# Create folium map\n",
    "m = folium.Map(location=[39.9526, -75.1652],zoom_start=11)\n",
    "m.choropleth(\n",
    "    geo_data=data,\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.2,\n",
    "    data=saleDate2020MIN_groupbyDF,\n",
    "    key_on='feature.properties.CODE',\n",
    "    columns=['zip_code','sale_price'],\n",
    "    fill_color='YlGnBu',\n",
    "    legend_name='Least Expensive Homes Sold by Zip, 2020'\n",
    ")\n",
    "folium.LayerControl().add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b0c553",
   "metadata": {},
   "source": [
    "## FInal observations\n",
    "* xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79294dda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
